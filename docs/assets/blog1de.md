 
Friday, 18 August 2023
14:18
 
OpenAI, beziehungsweise Generative AI, wird in vielen Microsoft-Produkten verwendet. Daher ist es wichtig, sich das ganze aus verschiedene Ebenen zu betrachten um ein Grundverständnis zu verbessern und mit sich mit internen und externen Stakeholdern auszutauschen. 

Es gibt verschiedene Kategorien/Level wie wir AI Services Beziehen können: 
 
| Kategorie                      | Beispiel                        | Kunden-Einfluss auf das Modell     |
|--------------------------------|---------------------------------|-----------------------------------|
| Anwendungsebene                | Microsoft Teams Premium         | Gering bis keine                  |
| Anwendungsplattform            | Power Virtual Agent              | Begrenzter Einfluss               |
| Szenariobasierte Services      | Azure Cognitive Search           | Eingeschränkter Einfluss          |
| Benutzerdefinierte KI-Modelle  | Azure Open AI, ChatGPT, Dell-E  | Stärkerer Einfluss                |
| ML-Plattform                   | Azure Machine Learning-Plattformen | Vollständiger Einfluss          |
 
Ein Beispiel für die Anwendungsebene ist Microsoft Teams Premium, das KI-Dienste verwendet, um Aufgaben aus einem Teams-Meeting basieren auf dem Video und Voice stream automatisch zu generieren. Die generierten Inhalte können jedoch nicht an kundenspezifische Inhalte angepasst werden, wie zum Beispiel interne Abkürzungen von Abteilungen oder Produkten. Anders gesagt, der Kunde kann keinen Einfluss auf das Modell nehmen. Anwendungsfälle sind vielfältig und hilfreich, jedoch auf die vorgesehenen Funktionen der Anwendung und des Herstellers beschränkt. Dies können sehr mächtige Applikationen sein. Schaut man sich M365 Copilot einmal an, hat man hier schon eine sehr beeindruckende Applikation.
 
Wenn wir uns die Anwendungsplattform anschauen, können wir hier Einfluss auf die Modelle mit unseren Daten nehmen, unter Verwendung von Generative AI durch den Hersteller. Dies gilt sowohl für die Eingaben als auch für die Ausgaben. Es werden auch kognitive Services oder sogar Maschine Learning verwendet, um das Modell mit spezifischen Fähigkeiten zu verbessern. So können beispielsweise bei Power Virtual Agent Workflows anhand von Eingaben erstellt werden oder Power App-Designs anhand von Bleistiftskizzen. Kunden können auch bestimmte Daten auslesen, klassifizieren und weiterverarbeiten. Allerdings ist man immer noch auf die vortrainierten Modelle beschränkt. 
 
Beispiele für Szenarien basierte Services, die KI beinhalten, sind Azure Cognitive Search, Form Recognizer, Metrics Advisors usw. Diese Services können von Apps konsumiert und in verschiedene Szenarien integriert werden. Azure Cognitive Search oder bald Vector Search (Vorschau) stellen out-of-the-box KI-Fähigkeiten zur Verfügung, wie z.B. exakte Schlüsselwortübereinstimmung, mehrsprachige Suche und semantische Suche, die in Anwendungen integriert werden können und das Benutzererlebnis verbessern können.
 
Customize AI Models haben aktuell eine hohe Strahlkraft, da Azure Open AI Teil dieser Kategorie ist. Neben Vision, Speech Languages & Decision AI Models können auch ChatGPT und Dell-E in Azure konsumiert werden. Diese Modelle sind schon lange verfügbar und werden eingesetzt, um unser Erlebnis zu verbessern, Kostendruck zu adressieren, aber auch komplett neue Produkte bis hin zu neuen Geschäftsmodellen zu entwickeln. Alle Services werden mithilfe von Kundendaten angereichert und trainiert. Es handelt sich jedoch immer noch um ein vortrainiertes Modell von Microsoft. Man könnte sagen, dass hier ein eigener Geschmack eines vortrainierten Modells erzeugt wird.
 
Die ML-Plattform gibt einem die Möglichkeit, eigene Modelle basierend auf eigenen Daten zu trainieren. Man ist nicht abhängig davon, wie gut ein vortrainiertes Modell ist. Sowohl Trainingsdaten als auch Testdaten kommen von Kunden. Data Preparation, Build und Train, Validate, Deploy sowie Managed and Monitor sind in Kundenhand.

AI Services können je nach Use Case und technischer Verfügbarkeit kombiniert werden. Daher ist eine Kostenanalyse basierend auf einem Businessplan und den Anforderungen für ein KI-Projekt empfohlen. 
 
Man merkt schnell das wenn man sich den Möglichkeiten KI Projekte ausschließlich von der Kostenseite nähert man eventuell wichtige Entscheidungskriterien vernachlässigt. Allerdings ist ein Verständnis verschiedener Kostenstrukturen für AI-Dienste in Microsoft-Produkten natürlich sinnvoll und hilfreich. 

Die Kosten für KI-Dienste variieren je nach Anwendungsfall und sollten immer im Kontext des geschäftlichen Nutzens betrachtet werden. Hier ist eine Übersicht über die Kostenstrukturen, die Ihnen eine erste Vorstellung davon geben, wie sich Beschaffungskosten zusammensetzen könnten:

|     | Beispiele                                        | Kostenstruktur                                                                                      |
|-----|--------------------------------------------------|----------------------------------------------------------------------------------------------------|
| Anwendung         | Microsoft Teams Premium, Microsoft Copilot       | Preis pro Benutzer/ Pre-Paid/Monat                                                                  |
| Plattform         | Power Virtual Agent, Power Automate, AI Builder  | Unterschiedliche Preismodelle, Per user, Per Services Credits, Pre-Paid / Monat, Abhängig von Einheiten (Textzeichen, Bilder, Seiten) |
| Szenariobasiert   | Azure Cognitive Services, Form Recognizer, etc. | Nutzungsabhängige Kosten, Pay-as-you-go, Commitment-Tier                                           |
| Azure Cognitive Search | Azure Cognitive Search                          | Kosten abhängig von Tier-Modell, Einheiten in der Zeit, Speichertyp                                |
| Angewandte KI / Cognitive Services | Open AI-Modelle                      | Pro Token, abhängig vom Modelltyp und Anzahl der verarbeiteten Tokens                              |
| Azure Machine Learning-Plattformen | Azure Machine Learning-Plattformen        | Abhängig von Zeiteinheit, Compute-Ressourcen, Tokens, Chats Commitments                            |

Ein wichtiger Aspekt, den Einkäufer und Techniker berücksichtigen sollten, ist der Einfluss von Commitments auf die Kosten. In vielen Fällen bieten längere Bindungen an KI-Dienste Kostenvorteile in Bezug auf Zeit und Rechenleistung. Diese Commitments können sich als kluge Investition erweisen, um langfristig Kosten zu senken und die Kontrolle über die Ausgaben zu behalten.

Schlussfolgerung:
Die Wahl der richtigen KI-Dienste für Ihr Unternehmen erfordert ein umfassendes Verständnis der Kostenstrukturen. Es ist wichtig, nicht nur die unmittelbaren Kosten, sondern auch den geschäftlichen Nutzen und die langfristigen Auswirkungen zu berücksichtigen. Jede Ebene der KI-Dienste bietet spezifische Kostenmodelle, die an den Anwendungsfall und die Unternehmensanforderungen angepasst werden können. Durch sorgfältige Planung, die Berücksichtigung von Commitments und die Ausrichtung auf die Geschäftsziele können Einkäufer und Techniker sicherstellen, dass die Implementierung von KI-Diensten sowohl wirtschaftlich als auch strategisch vorteilhaft ist.
 
 
Wichtig ist es auch sich um Skalierbarkeit und Nutzungsvolumen gedanken zu machen um Kosten langfristig unter Kontrolle zu halten. Viel muss nicht immer mehr kosten. Alle Services sind in der Cloud skalierbar. Auch wenn jeder Service sicher technische Grenzen hat, gibt es immer Möglichkeiten, sie weiter auszubauen. Es ist aber zu empfehlen, sich anzuschauen, wann welche Ressourcen gebraucht werden, welches Nutzungsverhalten vorliegt und ob es Lastspitzen gibt. Wenn man mit ML-Modellen arbeitet, sollte man eine Kosten-Nutzungs-Betrachtung der Ressourcen machen, die Utilization überwachen und die temporäre Bereitstellung von Ressourcen von Anfang an mit berücksichtigen, um unnötige Kostentreiber von Anfang an zu vermeiden. Eine DevOps-Strategie kann hier hohe Optimierungspotenziale freisetzen.
 
Immer wieder scheint dieses Thema Kostenkontrolle zu wenig Beachtung zu finden. Wir verhandeln einmal im Jahr einen Vertrag, dann trifft man sich wieder nach 3 Jahren und alle sind unglücklich. Meiner Meinung nach sollten Unternehmen und Partner sich bemühen, Kosten immer verursachungsgerecht zuzuordnen. Das spart nicht nur Kosten, sondern liefert auch klare Argumente, warum ein Service genutzt wird bzw. nicht mehr genutzt werden sollte. Gerne auch auf verschiedenen Ebenen wie Kostenstellen, Produkten, Kampagnen usw. Klar, es ist nicht immer möglich, da Ressourcen auch immer von mehr als einem Verursacher genutzt werden, trotzdem sollten alle Aktivitäten darauf abzielen, von einer reinen Kostenbetrachtung von IT-Services hin zu einer Ertragsbetrachtung zu gelangen. Hier sollten sich sinnvolle Konzepte überlegt werden, um die Steuerung von AI-Projekten sicherzustellen. 

AI-Projekte haben immer Projekt kosten. Auch wenn eine AI auf Anwendungsebene als Add-On eingeführt wird und keine Entwicklungskosten anfallen, ist die Adoption dieser neuen Services nicht zu unterschätzen. Typischerweise werden solche Projekte in Sprints geplant, im Rhythmus von 14 Tagen. Die Sprints können mit "T-Shirt Sizes" bepreist werden und bieten so Flexibilität innerhalb eines festen Preises pro Sprint, um agile Arbeitsweisen mit einem gewissen Kostenkontrollgrad zu implementieren. Oftmals handelt es sich dabei auch nicht um eine Make-or-Buy-Betrachtung, sondern eher um eine strategische Entscheidung, da weder der Kunde noch der Dienstleister alle Themenbereiche abdecken kann und Verantwortlichkeiten abgeben sollte. Da die Entwicklung der Modelle schnell voranschreitet, ist eine agile Methode, die auf Wert abzielt und die Zusammenarbeit mit Partnern beinhaltet, zu empfehlen. Eine 100%ige Auslagerung ist in den meisten Fällen nicht vorteilhaft, da das Prozess-Know-how und die Verantwortung für die Daten beim Kunden verbleiben sollten und nicht delegiert werden können.
 
Kommen wir zu einen der komplexere Kostenblöcken: Support- und managend Servicekosten. Wahrscheinlich eines der wichtigsten Themen, wenn es um langfristige Kostentreiber geht. Während technischer Support auf den herkömmlichen IT-Services und auch entwickelten Anwendungen noch relativ einfach zu bepreisen und zu vergleichen sind, können support und managend Services kosten  im ML-Bereich aufgrund ihrer Anforderungen möglicherweise komplexer sein. Nahe liegende Themen sollten aus einer Anwendungssicht zusammengefasst werden, und der Partner sollte pro Thema und Expertise Services konsolidiert betrachten (aus einer Hand), auch wenn möglicherweise Basis-Servi
 f ces anderswo kostengünstiger erhältlich sind. Langfristig sind die Kosten höher, wenn ein Service auf zu viele einzelne Verantwortungen aufgeteilt wird. Innerhalb eines AI-Projekts, auch in der Prototypenphase, sollte der Support- und Servicegedanke auch aus Kostensicht immer mitgedacht werden. Ein Servicekostenkorridor sollte definiert werden und Mehrwerte sollten hinterfragt werden, um hohe Kosten bei schlechtem Service zu vermeiden.

Infrastrukturkosten können erst wirklich bestimmt werden, wenn der Scope bekannt ist. Es lohnt sich immer, je nach Scope und wenn die Infrastrukturkosten bestimmt wurden, noch einmal über die Total Cost of Ownership-Kosten nachzudenken, vor allem im Bereich Services. Es könnte Sinn machen, eventuell einzelne Services direkt beim Hersteller zu beziehen, um Servicekosten und das Gesamterlebnis über die Laufzeit optimal zu gestalten – und auch andersrum. Sollte man Plannungssicherheit bei der Konsumtion bezüglich Infrastruktur haben, könnten sich dadurch Kostenvorteile ergeben.
Vertragsbedingungen und Laufzeiten. 

Alle Services können über die gängigen Vertragsmodelle von Microsoft bezogen werden. Es ist zu empfehlen, sich als ersten Schritt mit den Services einmal kostenlos vertraut zu machen. Dies können Sie einfach im Azure Portal anlegen. Es benötigt eine Freigabe von Microsoft, bevor sie OpenAI genutzt werden kann. Den entsprechenden Link findet man im Azure Portal beim Anlegen der OpenAI Services. Hier sollte man auch einmal die Terms & Conditions evaluieren lassen, bevor man den ersten Schritt in eine AI Journey wagt.

Kosten bezüglich Integration und Kompatibilität sind nicht zu unterschätzen und entpuppen sich langfristig als Kostentreiber. Oftmals sind Unternehmen noch gar nicht so weit, AI-Modelle effizient zu nutzen, zu trainieren, weil Daten einfach nicht so verfügbar sind wie sie benötigt werden. Es lohnt sich oft, hier bei der Evaluierung eines Projektes sich intensiv damit auseinanderzusetzen, um nicht später von Folgeprojekten, Infrastruktur- und Servicekosten überrascht zu werden. 

Wir sehen das KI-Projekte nicht ausschließlich kostenseitig betrachtet werden sollten. Es ist wichtig, grundlegende Strukturen für eine Total Cost of Value Betrachtung zu schaffen. Denn abgesehen davon, dass es eine coole Technologie ist, gibt es zahlreiche Geschäftsfälle, die zeigen, dass die Implementierung von KI in nahezu allen Bereichen sinnvoll ist.
Oftmals besteht die Sorge, dass KI Arbeitsplätze vernichtet. Doch in der Realität gibt es oft keine andere Wahl, da bestimmte Aufgaben einfach nicht effektiv von Menschen erledigt werden können. Entweder sind die Ressourcen nicht verfügbar oder die menschliche Arbeitskraft reicht nicht aus, um das Problem zu lösen.
Lassen Sie uns einen konkreten Fall betrachten: die Implementierung eines Voice Assistenten (Bot) in einem kleinen Kontaktzentrum in Deutschland. Aktuell arbeiten dort fünf Agenten und es gehen durchschnittlich 60 Anrufe pro Tag ein. Die meisten Anrufen sind zwischen 9 und 10 Uhr. Morgen können also viele Anrufe angenommen werden und nachmittags gibt es viele Lehrzeiten. Das Ziel ist es, die Effizienz und Auslastung der Agenten zu verbessern, Wartezeiten bei Anrufen zu reduzieren und den Kundenservice zu optimieren. Dies soll erreicht werden, indem Anrufe basierend auf dem Thema an den geeignetsten Agenten weitergeleitet werden und automatisierte Unterstützung in bestimmten Szenarien bereitgestellt wird.

Drei Anwendungsfälle mit einem voicebot können dies erreichen:

Ein Voicebot kann bessere und benutzerfreundlichere Routing-Entscheidungen treffen als jede herkömmliche interaktive Sprachantwort (IVR) heute. Kunden, die zu Stoßzeiten nicht bedient werden können, erhalten Terminvorschläge für Rückrufzeiten, die der Benutzer einfach auswählen kann. Zusätzlich kann der Bot selbst 25 % der Anfragen beantworten.

Die Implementierung eines voicebots bietet zahlreiche Vorteile. Doch wie können Sie den Return on Investment (ROI) über einen Zeitraum von drei Jahren berechnen? Indem Sie die erwarteten Kosteneinsparungen durch die Reduzierung der Wartezeiten und die verbesserte Effizienz der Agenten mit den Kosten für die Implementierung und Wartung des voicebots vergleichen. Sie werden schnell erkennen, dass die Einführung von KI-Services allen Beteiligten zugutekommt.
 
Insgesamt zeigt sich, dass die Einführung von KI in Ihrem Unternehmen weitreichende Vorteile mit sich bringt. Von der Verbesserung des Kundenservice über die Effizienzsteigerung bis hin zur Reduzierung von Wartezeiten - KI kann Ihnen helfen, Ihre Geschäftsziele zu erreichen. Nehmen Sie sich die Zeit, um die verschiedenen Anwendungsfälle zu analysieren und den ROI zu berechnen. Sie werden feststellen, dass die Implementierung von KI-Services eine Investition ist, die sich langfristig auszahlt. Oder es einmal mit den Worten einer meine Kunden sagen – The Business Case are Nuts. 
